{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d10a38-13a9-41f5-b1cd-a6abb69c3419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from gpytorch.module import Module\n",
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "def default_postprocess_script(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class Distance1(torch.nn.Module):\n",
    "    def __init__(self, postprocess_script=default_postprocess_script):\n",
    "        super().__init__()\n",
    "        self._postprocess = postprocess_script\n",
    "\n",
    "    def _sq_dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        \n",
    "        res = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "\n",
    "        if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "            pass\n",
    "#             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "        # Zero out negative values\n",
    "        res.clamp_min_(0)\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "        res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "        res = res.clamp_min_(1e-30).sqrt_()\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Kernel(Module):\n",
    "\n",
    "    has_lengthscale = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ard_num_dims=None,\n",
    "        batch_shape=torch.Size([]),\n",
    "        active_dims=None,\n",
    "        lengthscale_prior=None,\n",
    "        lengthscale_constraint=None,\n",
    "        eps=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Kernel, self).__init__()\n",
    "        self._batch_shape = batch_shape\n",
    "        if active_dims is not None and not torch.is_tensor(active_dims):\n",
    "            active_dims = torch.tensor(active_dims, dtype=torch.long)\n",
    "        self.register_buffer(\"active_dims\", active_dims)\n",
    "        self.ard_num_dims = ard_num_dims\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "        param_transform = kwargs.get(\"param_transform\")\n",
    "\n",
    "        if lengthscale_constraint is None:\n",
    "            lengthscale_constraint = Positive()\n",
    "\n",
    "        if param_transform is not None:\n",
    "            warnings.warn(\n",
    "                \"The 'param_transform' argument is now deprecated. If you want to use a different \"\n",
    "                \"transformation, specify a different 'lengthscale_constraint' instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        if self.has_lengthscale:\n",
    "            lengthscale_num_dims = 1 if ard_num_dims is None else ard_num_dims\n",
    "            self.register_parameter(\n",
    "                name=\"raw_lengthscale\",\n",
    "                parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, lengthscale_num_dims)),\n",
    "            )\n",
    "            if lengthscale_prior is not None:\n",
    "                self.register_prior(\n",
    "                    \"lengthscale_prior\", lengthscale_prior, lambda m: m.lengthscale, lambda m, v: m._set_lengthscale(\n",
    "                        v)\n",
    "                )\n",
    "\n",
    "            self.register_constraint(\"raw_lengthscale\", lengthscale_constraint)\n",
    "\n",
    "        self.distance_module = None\n",
    "        # TODO: Remove this on next official PyTorch release.\n",
    "        self.__pdist_supports_batch = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x1, x2, diag=False, last_dim_is_batch=False, **params):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        kernels = list(self.sub_kernels())\n",
    "        if len(kernels):\n",
    "            return _mul_broadcast_shape(self._batch_shape, *[k.batch_shape for k in kernels])\n",
    "        else:\n",
    "            return self._batch_shape\n",
    "\n",
    "    @batch_shape.setter\n",
    "    def batch_shape(self, val):\n",
    "        self._batch_shape = val\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.lengthscale.dtype\n",
    "        else:\n",
    "            for param in self.parameters():\n",
    "                return param.dtype\n",
    "            return torch.get_default_dtype()\n",
    "\n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"\n",
    "        Property to indicate whether kernel is stationary or not.\n",
    "        \"\"\"\n",
    "        return self.has_lengthscale\n",
    "\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not self.has_lengthscale:\n",
    "            raise RuntimeError(\"Kernel has no lengthscale.\")\n",
    "\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "\n",
    "        self.initialize(\n",
    "            raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def local_load_samples(self, samples_dict, memo, prefix):\n",
    "        num_samples = next(iter(samples_dict.values())).size(0)\n",
    "        self.batch_shape = torch.Size([num_samples]) + self.batch_shape\n",
    "        super().local_load_samples(samples_dict, memo, prefix)\n",
    "\n",
    "    def covar_dist(\n",
    "        self,\n",
    "        x1,\n",
    "        x2,\n",
    "        diag=False,\n",
    "        last_dim_is_batch=False,\n",
    "        square_dist=True,\n",
    "        dist_postprocess_func=default_postprocess_script,\n",
    "        postprocess=True,\n",
    "        **params,\n",
    "    ):\n",
    "\n",
    "        if last_dim_is_batch:\n",
    "            x1 = x1.transpose(-1, -2).unsqueeze(-1)\n",
    "            x2 = x2.transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        x1_eq_x2 = torch.equal(x1, x2)\n",
    "\n",
    "        # torch scripts expect tensors\n",
    "        postprocess = torch.tensor(postprocess)\n",
    "\n",
    "        res = None\n",
    "\n",
    "        # Cache the Distance object or else JIT will recompile every time\n",
    "        if not self.distance_module or self.distance_module._postprocess != dist_postprocess_func:\n",
    "            self.distance_module = Distance1(dist_postprocess_func)\n",
    "\n",
    "        if diag:\n",
    "            # Special case the diagonal because we can return all zeros most of\n",
    "            # the time.\n",
    "            if x1_eq_x2:\n",
    "                res = torch.zeros(*x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device)\n",
    "                if postprocess:\n",
    "                    res = dist_postprocess_func(res)\n",
    "                return res\n",
    "            else:\n",
    "                res = torch.norm(x1 - x2, p=2, dim=-1)\n",
    "                if square_dist:\n",
    "                    res = res.pow(2)\n",
    "            if postprocess:\n",
    "                res = dist_postprocess_func(res)\n",
    "            return res\n",
    "\n",
    "        elif square_dist:\n",
    "            res = self.distance_module._sq_dist(x1, x2, postprocess, x1_eq_x2)\n",
    "        else:\n",
    "            res = self.distance_module._dist(x1, x2, postprocess, x1_eq_x2)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def named_sub_kernels(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if module is not self and isinstance(module, Kernel):\n",
    "                yield name, module\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        How many outputs are produced per input (default 1)\n",
    "        if x1 is size `n x d` and x2 is size `m x d`, then the size of the kernel\n",
    "        will be `(n * num_outputs_per_input) x (m * num_outputs_per_input)`\n",
    "        Default: 1\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    def prediction_strategy(self, train_inputs, train_prior_dist, train_labels, likelihood):\n",
    "        return exact_prediction_strategies.DefaultPredictionStrategy(\n",
    "            train_inputs, train_prior_dist, train_labels, likelihood\n",
    "        )\n",
    "\n",
    "    def sub_kernels(self):\n",
    "        for _, kernel in self.named_sub_kernels():\n",
    "            yield kernel\n",
    "\n",
    "    def __call__(self, x1, x2=None, diag=False, last_dim_is_batch=False, **params):\n",
    "        x1_, x2_ = x1, x2\n",
    "\n",
    "        # Select the active dimensions\n",
    "        if self.active_dims is not None:\n",
    "            x1_ = x1_.index_select(-1, self.active_dims)\n",
    "            if x2_ is not None:\n",
    "                x2_ = x2_.index_select(-1, self.active_dims)\n",
    "\n",
    "        # Give x1_ and x2_ a last dimension, if necessary\n",
    "        if x1_.ndimension() == 1:\n",
    "            x1_ = x1_.unsqueeze(1)\n",
    "        if x2_ is not None:\n",
    "            if x2_.ndimension() == 1:\n",
    "                x2_ = x2_.unsqueeze(1)\n",
    "            if not x1_.size(-1) == x2_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"x1_ and x2_ must have the same number of dimensions!\")\n",
    "\n",
    "        if x2_ is None:\n",
    "            x2_ = x1_\n",
    "\n",
    "        # Check that ard_num_dims matches the supplied number of dimensions\n",
    "        if settings.debug.on():\n",
    "            if self.ard_num_dims is not None and self.ard_num_dims != x1_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"Expected the input to have {} dimensionality \"\n",
    "                    \"(based on the ard_num_dims argument). Got {}.\".format(\n",
    "                        self.ard_num_dims, x1_.size(-1))\n",
    "                )\n",
    "\n",
    "        if diag:\n",
    "            res = super(Kernel, self).__call__(x1_, x2_, diag=True,\n",
    "                                               last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            # Did this Kernel eat the diag option?\n",
    "            # If it does not return a LazyEvaluatedKernelTensor, we can call\n",
    "            # diag on the output\n",
    "            if not isinstance(res, LazyEvaluatedKernelTensor):\n",
    "                if res.dim() == x1_.dim() and res.shape[-2:] == torch.Size((x1_.size(-2), x2_.size(-2))):\n",
    "                    res = res.diag()\n",
    "            return res\n",
    "\n",
    "        else:\n",
    "            if settings.lazily_evaluate_kernels.on():\n",
    "                res = LazyEvaluatedKernelTensor(\n",
    "                    x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            else:\n",
    "                res = lazify(super(Kernel, self).__call__(\n",
    "                    x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n",
    "            return res\n",
    "\n",
    "    def __getstate__(self):\n",
    "        # JIT ScriptModules cannot be pickled\n",
    "        self.distance_module = None\n",
    "        return self.__dict__\n",
    "\n",
    "    def __add__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, AdditiveKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               AdditiveKernel) else [other]\n",
    "        return AdditiveKernel(*kernels)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, ProductKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               ProductKernel) else [other]\n",
    "        return ProductKernel(*kernels)\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if len(self.batch_shape) == 0:\n",
    "            return self\n",
    "\n",
    "        new_kernel = deepcopy(self)\n",
    "        # Process the index\n",
    "        index = index if isinstance(index, tuple) else (index,)\n",
    "\n",
    "        for param_name, param in self._parameters.items():\n",
    "            new_kernel._parameters[param_name].data = param.__getitem__(index)\n",
    "            ndim_removed = len(param.shape) - \\\n",
    "                len(new_kernel._parameters[param_name].shape)\n",
    "            new_batch_shape_len = len(self.batch_shape) - ndim_removed\n",
    "            new_kernel.batch_shape = new_kernel._parameters[\n",
    "                param_name].shape[:new_batch_shape_len]\n",
    "\n",
    "        for sub_module_name, sub_module in self.named_sub_kernels():\n",
    "            self._modules[sub_module_name] = sub_module.__getitem__(index)\n",
    "\n",
    "        return new_kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4256ccff-9c2e-4c92-bffe-7cfd08f72662",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92aa237e-997c-4209-9a48-7f9465b02322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dc7f71-7ea4-4400-b136-879b977c03bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 | 27% |  4% |\n",
      "|  2 |  0% |  6% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  5% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e3bd26-3cc4-4c92-8e68-4b409b927323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 2 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "output_device = torch.device('cuda:0')\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c43f83f2-063a-41bf-94f5-b2820d58531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "l = 8\n",
    "alphabet = list(range(alpha))\n",
    "\n",
    "# prob no mutation at time 1\n",
    "q = 1 - 1/l\n",
    "\n",
    "q = 1/2\n",
    "\n",
    "odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7a134600-fe2d-402b-9c3e-52055c9584cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = list(itertools.product(alphabet, repeat=l))\n",
    "seqs = torch.tensor(seqs).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6d5da275-1cbc-45c7-a8d1-9ea12348b351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46511627/ipykernel_14179/3888506446.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "08d8b855-3fc9-4be6-9df8-6428a4f0646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = seqs1h_test[:10]\n",
    "\n",
    "seqs2 = []\n",
    "for d in range(0, l+1):\n",
    "    seq = torch.zeros(l)\n",
    "    seq[:d] = 3\n",
    "    seqs2.append(seq)\n",
    "\n",
    "seqs2 = torch.stack(seqs2).type(torch.int64)\n",
    "\n",
    "x2 = F.one_hot(seqs2).type(torch.float32).to(output_device)\n",
    "x2 = torch.flatten(x2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f554155-c011-4afa-b187-710472881cc8",
   "metadata": {},
   "source": [
    "### Build Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e969557b-40b6-4a9a-95d3-56eedaef8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inverse for eigenvalue matrix for calculate K = \\sum b_k P'^k\n",
    "\n",
    "scaling_factors = np.array([(1 - q**t)**l for t in range(l+1)])\n",
    "scaling_factors[0] = 1\n",
    "eigvals = np.array([[np.exp(-k*t) for t in range(l+1)] for k in range(l+1)])\n",
    "eigvals = eigvals*scaling_factors\n",
    "\n",
    "coeffs = np.linalg.inv(eigvals)\n",
    "coeffs = torch.tensor(coeffs, dtype=torch.float32).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6c5a36a2-9b6b-4034-8f84-6a31ee4a491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)]).to(output_device)\n",
    "scaling_factors[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8fe47c27-f5e4-4dfa-9177-8195e7be8ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from gpytorch import settings\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.lazy import LazyEvaluatedKernelTensor, ZeroLazyTensor, delazify, lazify\n",
    "from gpytorch.models import exact_prediction_strategies\n",
    "from gpytorch.module import Module\n",
    "from gpytorch.utils.broadcasting import _mul_broadcast_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "a68db6df-cde5-46d1-bb35-bf4f31ef71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class SkewKernel(Kernel):\n",
    "    \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, alpha, l, odds,\n",
    "                log_lda_prior=None, log_lda_constraint=None, \n",
    "                log_p_prior=None, log_p_constraint=None,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "          name='raw_log_p', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l, alpha))\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\n",
    "          name='raw_log_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l+1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if log_lda_constraint is None:\n",
    "          log_lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        if log_p_constraint is None:\n",
    "          log_p_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_log_lda\", log_lda_constraint)\n",
    "        self.register_constraint(\"raw_log_p\", log_p_constraint)\n",
    "\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def log_lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_lda_constraint.transform(self.raw_log_lda)\n",
    "\n",
    "    @property\n",
    "    def log_p(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_p_constraint.transform(self.raw_log_p)\n",
    "\n",
    "    @log_lda.setter\n",
    "    def log_lda(self, value):\n",
    "      return self._set_log_lda(value)\n",
    "\n",
    "    @log_p.setter\n",
    "    def log_p(self, value):\n",
    "      return self._set_log_p(value)\n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, x1, x2, **params):\n",
    "#         # construct masks used for calculate rates\n",
    "#         masks = self.covar_dist(x1, x2)\n",
    "#         ps = torch.softmax(self.log_p, axis=1)\n",
    "\n",
    "#         rates = odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "#         rates = rates/ps\n",
    "#         rates = rates.to(output_device)\n",
    "#         rates = torch.flatten(rates, start_dim=1)\n",
    "#         log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "#         out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "#         out = torch.flatten(out, start_dim=3)\n",
    "# #         out[out==0.] = 1.\n",
    "\n",
    "#         powers_nz = torch.exp(torch.sum(out, -1))\n",
    "#         power_0 = F.relu(torch.sum(masks, -1) - l + 1)\n",
    "#         powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "\n",
    "#         weights = torch.matmul(coeffs.to(output_device), torch.exp(self.log_lda))\n",
    "        \n",
    "#         return torch.sum(torch.mul(powers, weights), -1)\n",
    "    \n",
    "    def func(self, x1, x2, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "        ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "        pi = x2*(torch.flatten(ps))\n",
    "        pi[pi==0.] = 1\n",
    "        pi = torch.prod(pi, 1)\n",
    "        Dpi = torch.diag(pi)        \n",
    "\n",
    "        rates = odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = rates.to(output_device)\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "#         out[out==0.] = 1.\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*scaling_factors\n",
    "        \n",
    "        return powers_nz, powers, rates\n",
    "\n",
    "    \n",
    "    def forward(self, x1, x2, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "        ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "        pi = x2*(torch.flatten(ps))\n",
    "        pi[pi==0.] = 1\n",
    "        pi = torch.prod(pi, 1)\n",
    "        Dpi = torch.diag(pi)        \n",
    "\n",
    "        rates = odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = rates.to(output_device)\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "#         out[out==0.] = 1.\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*scaling_factors\n",
    "        \n",
    "        weights = torch.matmul(coeffs.to(output_device), torch.exp(self.log_lda))\n",
    "        \n",
    "        return torch.sum(torch.mul(powers, weights), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6c8487b1-1219-4afb-949e-b3b082bc9993",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = SkewKernel(alpha, l, odds).to(output_device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
