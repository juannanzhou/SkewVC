{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1924bca6-ae9b-4187-b9af-65f092a89e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from gpytorch.module import Module\n",
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "def default_postprocess_script(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "class Distance1(torch.nn.Module):\n",
    "    def __init__(self, postprocess_script=default_postprocess_script):\n",
    "        super().__init__()\n",
    "        self._postprocess = postprocess_script\n",
    "\n",
    "    def _sq_dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        \n",
    "        res = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "\n",
    "        if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "            pass\n",
    "#             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "        # Zero out negative values\n",
    "        res.clamp_min_(0)\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "        res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "        res = res.clamp_min_(1e-30).sqrt_()\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Kernel(Module):\n",
    "\n",
    "    has_lengthscale = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ard_num_dims=None,\n",
    "        batch_shape=torch.Size([]),\n",
    "        active_dims=None,\n",
    "        lengthscale_prior=None,\n",
    "        lengthscale_constraint=None,\n",
    "        eps=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Kernel, self).__init__()\n",
    "        self._batch_shape = batch_shape\n",
    "        if active_dims is not None and not torch.is_tensor(active_dims):\n",
    "            active_dims = torch.tensor(active_dims, dtype=torch.long)\n",
    "        self.register_buffer(\"active_dims\", active_dims)\n",
    "        self.ard_num_dims = ard_num_dims\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "        param_transform = kwargs.get(\"param_transform\")\n",
    "\n",
    "        if lengthscale_constraint is None:\n",
    "            lengthscale_constraint = Positive()\n",
    "\n",
    "        if param_transform is not None:\n",
    "            warnings.warn(\n",
    "                \"The 'param_transform' argument is now deprecated. If you want to use a different \"\n",
    "                \"transformation, specify a different 'lengthscale_constraint' instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        if self.has_lengthscale:\n",
    "            lengthscale_num_dims = 1 if ard_num_dims is None else ard_num_dims\n",
    "            self.register_parameter(\n",
    "                name=\"raw_lengthscale\",\n",
    "                parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, lengthscale_num_dims)),\n",
    "            )\n",
    "            if lengthscale_prior is not None:\n",
    "                self.register_prior(\n",
    "                    \"lengthscale_prior\", lengthscale_prior, lambda m: m.lengthscale, lambda m, v: m._set_lengthscale(\n",
    "                        v)\n",
    "                )\n",
    "\n",
    "            self.register_constraint(\"raw_lengthscale\", lengthscale_constraint)\n",
    "\n",
    "        self.distance_module = None\n",
    "        # TODO: Remove this on next official PyTorch release.\n",
    "        self.__pdist_supports_batch = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x1, x2, diag=False, last_dim_is_batch=False, **params):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        kernels = list(self.sub_kernels())\n",
    "        if len(kernels):\n",
    "            return _mul_broadcast_shape(self._batch_shape, *[k.batch_shape for k in kernels])\n",
    "        else:\n",
    "            return self._batch_shape\n",
    "\n",
    "    @batch_shape.setter\n",
    "    def batch_shape(self, val):\n",
    "        self._batch_shape = val\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.lengthscale.dtype\n",
    "        else:\n",
    "            for param in self.parameters():\n",
    "                return param.dtype\n",
    "            return torch.get_default_dtype()\n",
    "\n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"\n",
    "        Property to indicate whether kernel is stationary or not.\n",
    "        \"\"\"\n",
    "        return self.has_lengthscale\n",
    "\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not self.has_lengthscale:\n",
    "            raise RuntimeError(\"Kernel has no lengthscale.\")\n",
    "\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "\n",
    "        self.initialize(\n",
    "            raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def local_load_samples(self, samples_dict, memo, prefix):\n",
    "        num_samples = next(iter(samples_dict.values())).size(0)\n",
    "        self.batch_shape = torch.Size([num_samples]) + self.batch_shape\n",
    "        super().local_load_samples(samples_dict, memo, prefix)\n",
    "\n",
    "    def covar_dist(\n",
    "        self,\n",
    "        x1,\n",
    "        x2,\n",
    "        diag=False,\n",
    "        last_dim_is_batch=False,\n",
    "        square_dist=True,\n",
    "        dist_postprocess_func=default_postprocess_script,\n",
    "        postprocess=True,\n",
    "        **params,\n",
    "    ):\n",
    "\n",
    "        if last_dim_is_batch:\n",
    "            x1 = x1.transpose(-1, -2).unsqueeze(-1)\n",
    "            x2 = x2.transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        x1_eq_x2 = torch.equal(x1, x2)\n",
    "\n",
    "        # torch scripts expect tensors\n",
    "        postprocess = torch.tensor(postprocess)\n",
    "\n",
    "        res = None\n",
    "\n",
    "        # Cache the Distance object or else JIT will recompile every time\n",
    "        if not self.distance_module or self.distance_module._postprocess != dist_postprocess_func:\n",
    "            self.distance_module = Distance1(dist_postprocess_func)\n",
    "\n",
    "        if diag:\n",
    "            # Special case the diagonal because we can return all zeros most of\n",
    "            # the time.\n",
    "            if x1_eq_x2:\n",
    "                res = torch.zeros(*x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device)\n",
    "                if postprocess:\n",
    "                    res = dist_postprocess_func(res)\n",
    "                return res\n",
    "            else:\n",
    "                res = torch.norm(x1 - x2, p=2, dim=-1)\n",
    "                if square_dist:\n",
    "                    res = res.pow(2)\n",
    "            if postprocess:\n",
    "                res = dist_postprocess_func(res)\n",
    "            return res\n",
    "\n",
    "        elif square_dist:\n",
    "            res = self.distance_module._sq_dist(x1, x2, postprocess, x1_eq_x2)\n",
    "        else:\n",
    "            res = self.distance_module._dist(x1, x2, postprocess, x1_eq_x2)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def named_sub_kernels(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if module is not self and isinstance(module, Kernel):\n",
    "                yield name, module\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        How many outputs are produced per input (default 1)\n",
    "        if x1 is size `n x d` and x2 is size `m x d`, then the size of the kernel\n",
    "        will be `(n * num_outputs_per_input) x (m * num_outputs_per_input)`\n",
    "        Default: 1\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    def prediction_strategy(self, train_inputs, train_prior_dist, train_labels, likelihood):\n",
    "        return exact_prediction_strategies.DefaultPredictionStrategy(\n",
    "            train_inputs, train_prior_dist, train_labels, likelihood\n",
    "        )\n",
    "\n",
    "    def sub_kernels(self):\n",
    "        for _, kernel in self.named_sub_kernels():\n",
    "            yield kernel\n",
    "\n",
    "    def __call__(self, x1, x2=None, diag=False, last_dim_is_batch=False, **params):\n",
    "        x1_, x2_ = x1, x2\n",
    "\n",
    "        # Select the active dimensions\n",
    "        if self.active_dims is not None:\n",
    "            x1_ = x1_.index_select(-1, self.active_dims)\n",
    "            if x2_ is not None:\n",
    "                x2_ = x2_.index_select(-1, self.active_dims)\n",
    "\n",
    "        # Give x1_ and x2_ a last dimension, if necessary\n",
    "        if x1_.ndimension() == 1:\n",
    "            x1_ = x1_.unsqueeze(1)\n",
    "        if x2_ is not None:\n",
    "            if x2_.ndimension() == 1:\n",
    "                x2_ = x2_.unsqueeze(1)\n",
    "            if not x1_.size(-1) == x2_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"x1_ and x2_ must have the same number of dimensions!\")\n",
    "\n",
    "        if x2_ is None:\n",
    "            x2_ = x1_\n",
    "\n",
    "        # Check that ard_num_dims matches the supplied number of dimensions\n",
    "        if settings.debug.on():\n",
    "            if self.ard_num_dims is not None and self.ard_num_dims != x1_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"Expected the input to have {} dimensionality \"\n",
    "                    \"(based on the ard_num_dims argument). Got {}.\".format(\n",
    "                        self.ard_num_dims, x1_.size(-1))\n",
    "                )\n",
    "\n",
    "        if diag:\n",
    "            res = super(Kernel, self).__call__(x1_, x2_, diag=True,\n",
    "                                               last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            # Did this Kernel eat the diag option?\n",
    "            # If it does not return a LazyEvaluatedKernelTensor, we can call\n",
    "            # diag on the output\n",
    "            if not isinstance(res, LazyEvaluatedKernelTensor):\n",
    "                if res.dim() == x1_.dim() and res.shape[-2:] == torch.Size((x1_.size(-2), x2_.size(-2))):\n",
    "                    res = res.diag()\n",
    "            return res\n",
    "\n",
    "        else:\n",
    "            if settings.lazily_evaluate_kernels.on():\n",
    "                res = LazyEvaluatedKernelTensor(\n",
    "                    x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            else:\n",
    "                res = lazify(super(Kernel, self).__call__(\n",
    "                    x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n",
    "            return res\n",
    "\n",
    "    def __getstate__(self):\n",
    "        # JIT ScriptModules cannot be pickled\n",
    "        self.distance_module = None\n",
    "        return self.__dict__\n",
    "\n",
    "    def __add__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, AdditiveKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               AdditiveKernel) else [other]\n",
    "        return AdditiveKernel(*kernels)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, ProductKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               ProductKernel) else [other]\n",
    "        return ProductKernel(*kernels)\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if len(self.batch_shape) == 0:\n",
    "            return self\n",
    "\n",
    "        new_kernel = deepcopy(self)\n",
    "        # Process the index\n",
    "        index = index if isinstance(index, tuple) else (index,)\n",
    "\n",
    "        for param_name, param in self._parameters.items():\n",
    "            new_kernel._parameters[param_name].data = param.__getitem__(index)\n",
    "            ndim_removed = len(param.shape) - \\\n",
    "                len(new_kernel._parameters[param_name].shape)\n",
    "            new_batch_shape_len = len(self.batch_shape) - ndim_removed\n",
    "            new_kernel.batch_shape = new_kernel._parameters[\n",
    "                param_name].shape[:new_batch_shape_len]\n",
    "\n",
    "        for sub_module_name, sub_module in self.named_sub_kernels():\n",
    "            self._modules[sub_module_name] = sub_module.__getitem__(index)\n",
    "\n",
    "        return new_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d43f678-3b11-4f84-88a7-e5e61f63390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpytorch\n",
    "from gpytorch import settings\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.lazy import LazyEvaluatedKernelTensor, ZeroLazyTensor, delazify, lazify\n",
    "from gpytorch.models import exact_prediction_strategies\n",
    "from gpytorch.module import Module\n",
    "from gpytorch.utils.broadcasting import _mul_broadcast_shape\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "class SkewKernel(Kernel):\n",
    "    \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, alpha, l, odds,\n",
    "                log_lda_prior=None, log_lda_constraint=None, \n",
    "                log_p_prior=None, log_p_constraint=None,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "          name='raw_log_p', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l, alpha))\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\n",
    "          name='raw_log_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l+1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if log_lda_constraint is None:\n",
    "          log_lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        if log_p_constraint is None:\n",
    "          log_p_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_log_lda\", log_lda_constraint)\n",
    "        self.register_constraint(\"raw_log_p\", log_p_constraint)\n",
    "\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def log_lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_lda_constraint.transform(self.raw_log_lda)\n",
    "\n",
    "    @property\n",
    "    def log_p(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_p_constraint.transform(self.raw_log_p)\n",
    "\n",
    "    @log_lda.setter\n",
    "    def log_lda(self, value):\n",
    "      return self._set_log_lda(value)\n",
    "\n",
    "    @log_p.setter\n",
    "    def log_p(self, value):\n",
    "      return self._set_log_p(value)\n",
    "\n",
    "    def func(self, x1, x2, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "        ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "        pi = x2*(torch.flatten(ps))\n",
    "        pi[pi==0.] = 1\n",
    "        pi = torch.prod(pi, 1)\n",
    "        Dpi = torch.diag(pi)        \n",
    "\n",
    "        rates = odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = rates.to(output_device)\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*scaling_factors\n",
    "        \n",
    "        return powers_nz, powers, rates\n",
    "\n",
    "    \n",
    "    def forward(self, x1, x2, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "        ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "        pi = x2*(torch.flatten(ps))\n",
    "        pi[pi==0.] = 1\n",
    "        pi = torch.prod(pi, 1)\n",
    "        Dpi = torch.diag(pi)        \n",
    "\n",
    "        rates = odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = rates.to(output_device)\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "#         out[out==0.] = 1.\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*scaling_factors\n",
    "        \n",
    "        weights = torch.matmul(coeffs.to(output_device), torch.exp(self.log_lda))\n",
    "        \n",
    "        return torch.sum(torch.mul(powers, weights), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9da57ec-236c-4fd7-a392-b3bee12f7045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkewVCModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ker):\n",
    "        super(SkewVCModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = ker\n",
    "#         base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "#         base_covar_module = ker\n",
    "\n",
    "\n",
    "#         self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "#             base_covar_module, device_ids=range(n_devices),\n",
    "#             output_device=output_device\n",
    "#         )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ff1daaa-998a-40ba-bb1c-535dd9eb563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkewVCModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ker):\n",
    "        super(SkewVCModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         self.covar_module = ker\n",
    "        base_covar_module = ker\n",
    "\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a4e46e5-db60-4088-9d9c-d1f481bfbdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, likelihood, train_x, train_y, checkpoint_size, preconditioner_size, training_iter=300, lr=.05):\n",
    "    losses = []\n",
    "    \n",
    "    \"\"\"fitting hyperparameters of model by maximizing marginal log likelihood\"\"\"\n",
    "    # Use the adam optimizer, this includes GaussianLikelihood parameters\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "      if i%20==0:\n",
    "        print(i)\n",
    "      else: pass\n",
    "      # Zero gradients from previous iteration\n",
    "    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "         gpytorch.settings.max_preconditioner_size(preconditioner_size):        \n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())    \n",
    "        optimizer.step()\n",
    "        del loss\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af93ae9-0741-41d3-a86b-2e32d007c505",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a345476c-d7e7-414a-9987-56cd1cae922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d3b7cb-deac-44b3-9723-90069c062a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "|  1 |  0% |  0% |\n",
      "|  2 |  0% |  0% |\n",
      "|  3 |  0% |  0% |\n",
      "|  4 |  0% |  0% |\n",
      "|  5 |  0% |  0% |\n",
      "|  6 |  0% |  0% |\n",
      "|  7 |  0% |  0% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "808db33e-7763-438e-91e2-661c68b00dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n"
     ]
    }
   ],
   "source": [
    "n_devices = torch.cuda.device_count()\n",
    "output_device = torch.device('cuda:0')\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919f5bd3-387e-45f2-b42f-9978ea4940c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "l = 8\n",
    "alphabet = list(range(alpha))\n",
    "\n",
    "# prob no mutation at time 1\n",
    "# q = 1 - 1/l\n",
    "q = 0.7\n",
    "\n",
    "odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]).to(output_device)\n",
    "\n",
    "scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)]).to(output_device)\n",
    "scaling_factors[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a9d5fcf-4d42-400b-8e37-61f837d18e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_18435/2187406656.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "seqs = list(itertools.product(alphabet, repeat=l))\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "seqs2 = []\n",
    "for d in range(0, l+1):\n",
    "    seq = torch.zeros(l)\n",
    "    seq[:d] = 3\n",
    "    seqs2.append(seq)\n",
    "\n",
    "seqs2 = torch.stack(seqs2).type(torch.int64)\n",
    "\n",
    "x1 = seqs1h_test[:10]\n",
    "x2 = F.one_hot(seqs2).type(torch.float32).to(output_device)\n",
    "x2 = torch.flatten(x2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1066dd-6414-46a8-99ee-d60deca1024d",
   "metadata": {},
   "source": [
    "#### Eigenvalues and inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51ed59f-97ae-408b-b2f2-bb88f90330e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = np.array([[q**(k*t) for t in range(l+1)] for k in range(l+1)])\n",
    "# eigvals = scaling_factors*eigvals\n",
    "eigvals = torch.tensor(eigvals, dtype=torch.float32).to(output_device)\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def calc_L_polynomial_coeffs():\n",
    "        '''\n",
    "        Calculates the coefficients of the polynomial in L that represent\n",
    "        projection matrices into each of the kth eigenspaces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        B : array-like of shape (seq_length + 1, seq_length + 1)\n",
    "            Matrix containing the b_i,k coefficients for power i on rows\n",
    "            and order k on columns. One can obtain the coefficients for any\n",
    "            combination of $\\lambda_k$ values by scaling the coefficients\n",
    "            for each eigenspace by its eigenvalue and adding them up across\n",
    "            different powers\n",
    "        '''\n",
    "\n",
    "        lambdas = np.array([q**k for k in range(l+1)])\n",
    "        s = l + 1\n",
    "        B = np.zeros((s, s))\n",
    "\n",
    "        idx = np.arange(s)\n",
    "\n",
    "        for k in idx:\n",
    "            k_idx = idx != k\n",
    "            k_lambdas = lambdas[k_idx]\n",
    "            norm_factor = 1 / np.prod(k_lambdas - lambdas[k])\n",
    "\n",
    "            for power in idx:\n",
    "                p = np.sum([np.product(v) for v in combinations(k_lambdas, l - power)])\n",
    "                B[power, k] = norm_factor * (-1) ** (power) * p\n",
    "\n",
    "        return(B)\n",
    "\n",
    "\n",
    "\n",
    "coeffs = calc_L_polynomial_coeffs()\n",
    "coeffs = torch.tensor(coeffs, dtype=torch.float32).to(output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048298e-d144-463d-9537-319bef7dcf5d",
   "metadata": {},
   "source": [
    "## SMN1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20682cd9-96ad-48ee-9b1f-859c25b749b7",
   "metadata": {},
   "source": [
    "#### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a939223d-29a2-4faf-9be2-e83a9dd220bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_18435/3022755038.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = pd.read_csv(\"smn1data.csv\", header=None)\n",
    "\n",
    "dat = dat.rename(columns={0:\"seq\", 1:\"psi\", 2:\"std\"})\n",
    "\n",
    "from collections import OrderedDict\n",
    "IUPAC_VOCAB_ = OrderedDict([\n",
    "    (\"A\", 0),\n",
    "    (\"U\", 1),\n",
    "    (\"C\", 2),\n",
    "    (\"G\", 3)])\n",
    "\n",
    "def tokenize(seq):\n",
    "    return [IUPAC_VOCAB_[char] for char in seq]\n",
    "\n",
    "seqs = [tokenize(seq) for seq in dat.seq]\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "\n",
    "seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "y = torch.tensor(dat.psi, dtype=torch.float32).to(output_device)\n",
    "\n",
    "import random\n",
    "train_ids = random.sample(range(len(seqs1h)), 6554)\n",
    "test_ids = random.sample(list(set(range((len(seqs1h)))).difference(train_ids)), 5000)\n",
    "\n",
    "train_x, test_x = seqs1h[train_ids], seqs1h[test_ids]\n",
    "train_y, test_y = y[train_ids], y[test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817740c1-e794-4643-b037-ee6134917369",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3a68537-ed95-4130-b55b-91925958567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernel = SkewKernel(alpha, l, odds)\n",
    "kernel = kernel.to(output_device)\n",
    "kernel.raw_log_lda = torch.nn.Parameter(torch.cat((torch.tensor([-100.]), -2*torch.arange(l))).to(output_device))\n",
    "\n",
    "ker = kernel(x2[0].unsqueeze(0), x2).evaluate()\n",
    "rho = ker.detach().cpu().numpy()[0]\n",
    "rho /= rho[0]\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(rho)\n",
    "plt.show()\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = SkewVCModel(train_x, train_y, likelihood, kernel).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c35cb92-af30-45d2-b4fb-29d00ecc6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise = np.array(dat['std'].iloc[train_ids])**2\n",
    "train_noise = torch.tensor(train_noise, dtype=torch.float32).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17fdad2c-95f7-49ca-88ab-a332297238d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_noise, learn_additional_noise=True).to(output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4cb259-63d5-485e-80b1-4578ec0573af",
   "metadata": {},
   "source": [
    "#### Test forward and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d291969f-41e0-4b9a-91e4-ac9a0c508db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12c08104-c110-46f7-baa9-acec8cf69d62",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/46713648/ipykernel_18435/2153280467.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mIn\u001b[0m \u001b[0mparticular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar1\u001b[0m \u001b[0mwould\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0malways\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mAddedDiagLazyTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mcovar2\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0madded_diag_lazy_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0mincluding\u001b[0m \u001b[0mall\u001b[0m \u001b[0msubobjects\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minternally\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \"\"\"\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyTensorRepresentationTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lazy_tsr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a lazy tensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mrepresentation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/kernel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    396\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLazyEvaluatedKernelTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x1_scattered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cached_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, inputs, kwargs, device_ids)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_kwargs\u001b[0;34m(inputs, kwargs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscatter_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;34mr\"\"\"Scatter with support for kwargs dictionary\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(inputs, target_gpus, dim)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# None, clearing the cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mscatter_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py\u001b[0m in \u001b[0;36mscatter_map\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscatter_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mScatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscatter_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, target_gpus, chunk_sizes, dim, input)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# Perform CPU to GPU copies in a background stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mstreams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_gpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;31m# Synchronize with the copy stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstreams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/parallel/comm.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(tensor, devices, chunk_sizes, dim, streams, out)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = model(train_x)\n",
    "loss = -mll(output, train_y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1cd2ed4a-25c5-4d8e-b2c9-2954ebb04844",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 40.97 GiB (GPU 0; 79.35 GiB total capacity; 23.23 GiB already allocated; 3.02 GiB free; 72.68 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/46511627/ipykernel_15763/2615341091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, function_dist, target, *params)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Get the log prob of the marginal distribution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_other_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Get log determininant and first part of quadratic form\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mcovar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0minv_quad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_quad_logdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_quad_rhs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mIn\u001b[0m \u001b[0mparticular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovar1\u001b[0m \u001b[0mwould\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0malways\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0mAddedDiagLazyTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mcovar2\u001b[0m \u001b[0mmight\u001b[0m \u001b[0mbe\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \"\"\"\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0madded_diag_lazy_tsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madded_diag_lazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_diag_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36mrepresentation_tree\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0mincluding\u001b[0m \u001b[0mall\u001b[0m \u001b[0msubobjects\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m \u001b[0minternally\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1515\u001b[0m         \"\"\"\n\u001b[0;32m-> 1516\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLazyTensorRepresentationTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1518\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor_representation_tree.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lazy_tsr)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"representation\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Is it a lazy tensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                 \u001b[0mrepresentation_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrepresentation_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mrepresentation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mevaluate_kernel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mtemp_active_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_active_dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/46511627/ipykernel_15763/53130674.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, **params)\u001b[0m\n\u001b[1;32m    268\u001b[0m                     x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\n\u001b[1;32m    269\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m                 res = lazify(super(Kernel, self).__call__(\n\u001b[0m\u001b[1;32m    271\u001b[0m                     x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/46511627/ipykernel_15763/3767674188.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, **params)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_rates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;31m#         out[out==0.] = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.97 GiB (GPU 0; 79.35 GiB total capacity; 23.23 GiB already allocated; 3.02 GiB free; 72.68 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "# Output from model\n",
    "output = model(train_x)\n",
    "\n",
    "loss = -mll(output, train_y)\n",
    "print(loss)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01a509-10c2-468a-b7b2-875154fdf0db",
   "metadata": {},
   "source": [
    "#### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "561e12ea-b107-4034-a693-eb95f7b0248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46511627/ipykernel_15763/1973996978.py:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.axes().set_aspect('equal')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.661516\n",
      "r2 = 0.661549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "f_preds = model(test_x)\n",
    "\n",
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()\n",
    "\n",
    "# epistatic\n",
    "# figure(figsize=(5, 5), dpi=80)\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.show()\n",
    "print('R2 = %f'%r2_score(y_test, f_mean))\n",
    "print('r2 = %f'%pearsonr(y_test, f_mean)[0]**2)\n",
    "# print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "030fdcf8-bc58-460e-8ae8-4ddcfb5cb932",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), .1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2c970798-cb61-4c2d-97a9-a3f521b0ff07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n",
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n",
      "1380\n",
      "1400\n",
      "1420\n",
      "1440\n",
      "1460\n",
      "1480\n",
      "1500\n",
      "1520\n",
      "1540\n",
      "1560\n",
      "1580\n",
      "1600\n",
      "1620\n",
      "1640\n",
      "1660\n",
      "1680\n",
      "1700\n",
      "1720\n",
      "1740\n",
      "1760\n",
      "1780\n",
      "1800\n",
      "1820\n",
      "1840\n",
      "1860\n",
      "1880\n",
      "1900\n",
      "1920\n",
      "1940\n",
      "1960\n",
      "1980\n",
      "2000\n",
      "2020\n",
      "2040\n",
      "2060\n",
      "2080\n",
      "2100\n",
      "2120\n",
      "2140\n",
      "2160\n",
      "2180\n",
      "2200\n",
      "2220\n",
      "2240\n",
      "2260\n",
      "2280\n",
      "2300\n",
      "2320\n",
      "2340\n",
      "2360\n",
      "2380\n",
      "2400\n",
      "2420\n",
      "2440\n",
      "2460\n",
      "2480\n",
      "2500\n",
      "2520\n",
      "2540\n",
      "2560\n",
      "2580\n",
      "2600\n",
      "2620\n",
      "2640\n",
      "2660\n",
      "2680\n",
      "2700\n",
      "2720\n",
      "2740\n",
      "2760\n",
      "2780\n",
      "2800\n",
      "2820\n",
      "2840\n",
      "2860\n",
      "2880\n",
      "2900\n",
      "2920\n",
      "2940\n",
      "2960\n",
      "2980\n",
      "3000\n",
      "3020\n",
      "3040\n",
      "3060\n",
      "3080\n",
      "3100\n",
      "3120\n",
      "3140\n",
      "3160\n",
      "3180\n",
      "3200\n",
      "3220\n",
      "3240\n",
      "3260\n",
      "3280\n",
      "3300\n",
      "3320\n",
      "3340\n",
      "3360\n",
      "3380\n",
      "3400\n",
      "3420\n",
      "3440\n",
      "3460\n",
      "3480\n",
      "3500\n",
      "3520\n",
      "3540\n",
      "3560\n",
      "3580\n",
      "3600\n",
      "3620\n",
      "3640\n",
      "3660\n",
      "3680\n",
      "3700\n",
      "3720\n",
      "3740\n",
      "3760\n",
      "3780\n",
      "3800\n",
      "3820\n",
      "3840\n",
      "3860\n",
      "3880\n",
      "3900\n",
      "3920\n",
      "3940\n",
      "3960\n",
      "3980\n",
      "4000\n",
      "4020\n",
      "4040\n",
      "4060\n",
      "4080\n",
      "4100\n",
      "4120\n",
      "4140\n",
      "4160\n",
      "4180\n",
      "4200\n",
      "4220\n",
      "4240\n",
      "4260\n",
      "4280\n",
      "4300\n",
      "4320\n",
      "4340\n",
      "4360\n",
      "4380\n",
      "4400\n",
      "4420\n",
      "4440\n",
      "4460\n",
      "4480\n",
      "4500\n",
      "4520\n",
      "4540\n",
      "4560\n",
      "4580\n",
      "4600\n",
      "4620\n",
      "4640\n",
      "4660\n",
      "4680\n",
      "4700\n",
      "4720\n",
      "4740\n",
      "4760\n",
      "4780\n",
      "4800\n",
      "4820\n",
      "4840\n",
      "4860\n",
      "4880\n",
      "4900\n",
      "4920\n",
      "4940\n",
      "4960\n",
      "4980\n",
      "5000\n",
      "5020\n",
      "5040\n",
      "5060\n",
      "5080\n",
      "5100\n",
      "5120\n",
      "5140\n",
      "5160\n",
      "5180\n",
      "5200\n",
      "5220\n",
      "5240\n",
      "5260\n",
      "5280\n",
      "5300\n",
      "5320\n",
      "5340\n",
      "5360\n",
      "5380\n",
      "5400\n",
      "5420\n",
      "5440\n",
      "5460\n",
      "5480\n",
      "5500\n",
      "5520\n",
      "5540\n",
      "5560\n",
      "5580\n",
      "5600\n",
      "5620\n",
      "5640\n",
      "5660\n",
      "5680\n",
      "5700\n",
      "5720\n",
      "5740\n",
      "5760\n",
      "5780\n",
      "5800\n",
      "5820\n",
      "5840\n",
      "5860\n",
      "5880\n",
      "5900\n",
      "5920\n",
      "5940\n",
      "5960\n",
      "5980\n",
      "6000\n",
      "6020\n",
      "6040\n",
      "6060\n",
      "6080\n",
      "6100\n",
      "6120\n",
      "6140\n",
      "6160\n",
      "6180\n",
      "6200\n",
      "6220\n",
      "6240\n",
      "6260\n",
      "6280\n",
      "6300\n",
      "6320\n",
      "6340\n",
      "6360\n",
      "6380\n",
      "6400\n",
      "6420\n",
      "6440\n",
      "6460\n",
      "6480\n",
      "6500\n",
      "6520\n",
      "6540\n",
      "6560\n",
      "6580\n",
      "6600\n",
      "6620\n",
      "6640\n",
      "6660\n",
      "6680\n",
      "6700\n",
      "6720\n",
      "6740\n",
      "6760\n",
      "6780\n",
      "6800\n",
      "6820\n",
      "6840\n",
      "6860\n",
      "6880\n",
      "6900\n",
      "6920\n",
      "6940\n",
      "6960\n",
      "6980\n",
      "7000\n",
      "7020\n",
      "7040\n",
      "7060\n",
      "7080\n",
      "7100\n",
      "7120\n",
      "7140\n",
      "7160\n",
      "7180\n",
      "7200\n",
      "7220\n",
      "7240\n",
      "7260\n",
      "7280\n",
      "7300\n",
      "7320\n",
      "7340\n",
      "7360\n",
      "7380\n",
      "7400\n",
      "7420\n",
      "7440\n",
      "7460\n",
      "7480\n",
      "7500\n",
      "7520\n",
      "7540\n",
      "7560\n",
      "7580\n",
      "7600\n",
      "7620\n",
      "7640\n",
      "7660\n",
      "7680\n",
      "7700\n",
      "7720\n",
      "7740\n",
      "7760\n",
      "7780\n",
      "7800\n",
      "7820\n",
      "7840\n",
      "7860\n",
      "7880\n",
      "7900\n",
      "7920\n",
      "7940\n",
      "7960\n",
      "7980\n",
      "tensor(3.4908, device='cuda:0', grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juannanzhou/.local/lib/python3.8/site-packages/gpytorch/utils/linear_cg.py:234: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [1, 11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:23.)\n",
      "  torch.sum(mul_storage, -2, keepdim=True, out=alpha)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_size = 0\n",
    "preconditioner_size = 100\n",
    "model.train()\n",
    "\n",
    "losses = train_model(model, likelihood, train_x, train_y, checkpoint_size, preconditioner_size, training_iter=8000, lr=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06637fb7-7dba-471e-aac9-268fbd9f22f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
