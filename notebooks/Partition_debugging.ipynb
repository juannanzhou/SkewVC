{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2433c64-c554-4c4b-823d-302a6a29a514",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38dafcc1-e398-4d96-9d51-d0d392506219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297a08b1-92f1-4bd2-8f2f-c2b1bd019f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "output_device = torch.device('cuda:0')\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828d090d-d1c3-423b-8fd2-964b86dedb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n",
      "|  1 |  0% |  2% |\n",
      "|  2 |  0% |  2% |\n",
      "|  3 |  0% |  2% |\n",
      "|  4 |  0% |  2% |\n",
      "|  5 |  0% |  2% |\n",
      "|  6 |  0% |  2% |\n",
      "|  7 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db040b53-2583-41c3-b23b-27fa0e4c7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 4\n",
    "l = 8\n",
    "alphabet = list(range(alpha))\n",
    "\n",
    "# prob no mutation at time 1\n",
    "# q = 1 - 1/l\n",
    "q = 0.7\n",
    "\n",
    "odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]).to(output_device)\n",
    "\n",
    "scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)]).to(output_device)\n",
    "scaling_factors[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a0da0f4-d868-496e-b2e3-9efcdb75d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd578f02-4ba4-4044-aefe-c03f35fe7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_91730/3240809624.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seqs = list(itertools.product(alphabet, repeat=l))\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "seqs2 = []\n",
    "for d in range(0, l+1):\n",
    "    seq = torch.zeros(l)\n",
    "    seq[:d] = 3\n",
    "    seqs2.append(seq)\n",
    "\n",
    "seqs2 = torch.stack(seqs2).type(torch.int64)\n",
    "\n",
    "x1 = seqs1h_test[:10]\n",
    "x2 = F.one_hot(seqs2).type(torch.float32).to(output_device)\n",
    "x2 = torch.flatten(x2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a27bd6-f2fe-4ef5-8b63-6e549eef7702",
   "metadata": {},
   "source": [
    "### SMN1 Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc091707-469a-45c9-893e-446557077f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_91730/2876302069.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = pd.read_csv(\"smn1data.csv\", header=None)\n",
    "\n",
    "dat = dat.rename(columns={0:\"seq\", 1:\"psi\", 2:\"std\"})\n",
    "\n",
    "from collections import OrderedDict\n",
    "IUPAC_VOCAB_ = OrderedDict([\n",
    "    (\"A\", 0),\n",
    "    (\"U\", 1),\n",
    "    (\"C\", 2),\n",
    "    (\"G\", 3)])\n",
    "\n",
    "def tokenize(seq):\n",
    "    return [IUPAC_VOCAB_[char] for char in seq]\n",
    "\n",
    "seqs = [tokenize(seq) for seq in dat.seq]\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "\n",
    "seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "y = torch.tensor(dat.psi, dtype=torch.float32).to(output_device)\n",
    "\n",
    "import random\n",
    "train_ids = random.sample(range(len(seqs1h)), 20000)\n",
    "test_ids = random.sample(list(set(range((len(seqs1h)))).difference(train_ids)), 100)\n",
    "\n",
    "train_x, test_x = seqs1h[train_ids], seqs1h[test_ids]\n",
    "train_y, test_y = y[train_ids], y[test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ad65d-0bd0-43d5-a8ac-4b735ed4246e",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5eaddb5-14c6-4426-b614-fb829711bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "from gpytorch.module import Module\n",
    "\n",
    "\n",
    "class SkewVCModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ker):\n",
    "        super(SkewVCModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        base_covar_module = ker\n",
    "\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaeb9632-fb0f-4f59-96a7-6659d0a36fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from gpytorch.module import Module\n",
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "def default_postprocess_script(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "# class Distance1(torch.nn.Module):\n",
    "#     def __init__(self, postprocess_script=default_postprocess_script):\n",
    "#         super().__init__()\n",
    "#         self._postprocess = postprocess_script\n",
    "\n",
    "#     def _sq_dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        \n",
    "#         res = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "\n",
    "#         if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "#             pass\n",
    "# #             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "#         # Zero out negative values\n",
    "#         res.clamp_min_(0)\n",
    "#         return self._postprocess(res) if postprocess else res\n",
    "\n",
    "#     def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "#         # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "#         res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "#         res = res.clamp_min_(1e-30).sqrt_()\n",
    "#         return self._postprocess(res) if postprocess else res\n",
    "\n",
    "class Distance1(torch.nn.Module):\n",
    "    def __init__(self, postprocess_script=default_postprocess_script):\n",
    "        super().__init__()\n",
    "        self._postprocess = postprocess_script\n",
    "\n",
    "    def _sq_dist(self, x1, x2, postprocess=None, x1_eq_x2=False):\n",
    "        # TODO: use torch squared cdist once implemented: https://github.com/pytorch/pytorch/pull/25799\n",
    "#         adjustment = x1.mean(-2, keepdim=True)\n",
    "#         x1 = x1 - adjustment\n",
    "#         x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "        # Compute squared distance matrix using quadratic expansion\n",
    "#         x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "#         x1_pad = torch.ones_like(x1_norm)\n",
    "#         if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "#             x2_norm, x2_pad = x1_norm, x1_pad\n",
    "#         else:\n",
    "#             x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "#             x2_pad = torch.ones_like(x2_norm)\n",
    "#         x1_ = torch.cat([-2.0 * x1, x1_norm, x1_pad], dim=-1)\n",
    "#         x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "#         res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "        res = x1.matmul(x2.transpose(-2, -1))        \n",
    "\n",
    "        if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "            pass\n",
    "#             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "        # Zero out negative values\n",
    "        res.clamp_min_(0)\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "        res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "        res = res.clamp_min_(1e-30).sqrt_()\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46aa695f-a83c-4726-a557-5fc6269ae43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance1(torch.nn.Module):\n",
    "    def __init__(self, postprocess_script=default_postprocess_script):\n",
    "        super().__init__()\n",
    "        self._postprocess = postprocess_script\n",
    "\n",
    "    def _sq_dist(self, x1, x2, postprocess=None, x1_eq_x2=False):\n",
    "        # TODO: use torch squared cdist once implemented: https://github.com/pytorch/pytorch/pull/25799\n",
    "#         adjustment = x1.mean(-2, keepdim=True)\n",
    "#         x1 = x1 - adjustment\n",
    "#         x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "        # Compute squared distance matrix using quadratic expansion\n",
    "#         x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "#         x1_pad = torch.ones_like(x1_norm)\n",
    "#         if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "#             x2_norm, x2_pad = x1_norm, x1_pad\n",
    "#         else:\n",
    "#             x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "#             x2_pad = torch.ones_like(x2_norm)\n",
    "#         x1_ = torch.cat([-2.0 * x1, x1_norm, x1_pad], dim=-1)\n",
    "#         x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "#         res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "        factors = 10**(.5*torch.arange(x1.shape[1])).to(x1.device)\n",
    "        x1_ = x1*factors\n",
    "        x2_ = x2*factors\n",
    "\n",
    "\n",
    "        res = x1_.matmul(x2_.transpose(-2, -1))        \n",
    "\n",
    "        if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "            pass\n",
    "#             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "        # Zero out negative values\n",
    "        res.clamp_min_(0)\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "        res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "        res = res.clamp_min_(1e-30).sqrt_()\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2813002f-1ef3-4db8-a2f7-83d603420e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Distance1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d5f06a9-e406-44b1-b8c1-a54ead361f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = D._sq_dist(x1, x2)[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b462f6ad-4d24-4a4a-a559-71963be7eb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfdd84-3155-4405-a0db-7a604f0118b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aac84e80-a5b7-4184-b9aa-45d3bef57875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Kernel(Module):\n",
    "\n",
    "    has_lengthscale = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ard_num_dims=None,\n",
    "        batch_shape=torch.Size([]),\n",
    "        active_dims=None,\n",
    "        lengthscale_prior=None,\n",
    "        lengthscale_constraint=None,\n",
    "        eps=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Kernel, self).__init__()\n",
    "        self._batch_shape = batch_shape\n",
    "        if active_dims is not None and not torch.is_tensor(active_dims):\n",
    "            active_dims = torch.tensor(active_dims, dtype=torch.long)\n",
    "        self.register_buffer(\"active_dims\", active_dims)\n",
    "        self.ard_num_dims = ard_num_dims\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "        param_transform = kwargs.get(\"param_transform\")\n",
    "\n",
    "        if lengthscale_constraint is None:\n",
    "            lengthscale_constraint = Positive()\n",
    "\n",
    "        if param_transform is not None:\n",
    "            warnings.warn(\n",
    "                \"The 'param_transform' argument is now deprecated. If you want to use a different \"\n",
    "                \"transformation, specify a different 'lengthscale_constraint' instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        if self.has_lengthscale:\n",
    "            lengthscale_num_dims = 1 if ard_num_dims is None else ard_num_dims\n",
    "            self.register_parameter(\n",
    "                name=\"raw_lengthscale\",\n",
    "                parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, lengthscale_num_dims)),\n",
    "            )\n",
    "            if lengthscale_prior is not None:\n",
    "                self.register_prior(\n",
    "                    \"lengthscale_prior\", lengthscale_prior, lambda m: m.lengthscale, lambda m, v: m._set_lengthscale(\n",
    "                        v)\n",
    "                )\n",
    "\n",
    "            self.register_constraint(\"raw_lengthscale\", lengthscale_constraint)\n",
    "\n",
    "        self.distance_module = None\n",
    "        # TODO: Remove this on next official PyTorch release.\n",
    "        self.__pdist_supports_batch = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x1, x2, diag=False, last_dim_is_batch=False, **params):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        kernels = list(self.sub_kernels())\n",
    "        if len(kernels):\n",
    "            return _mul_broadcast_shape(self._batch_shape, *[k.batch_shape for k in kernels])\n",
    "        else:\n",
    "            return self._batch_shape\n",
    "\n",
    "    @batch_shape.setter\n",
    "    def batch_shape(self, val):\n",
    "        self._batch_shape = val\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.lengthscale.dtype\n",
    "        else:\n",
    "            for param in self.parameters():\n",
    "                return param.dtype\n",
    "            return torch.get_default_dtype()\n",
    "\n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"\n",
    "        Property to indicate whether kernel is stationary or not.\n",
    "        \"\"\"\n",
    "        return self.has_lengthscale\n",
    "\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not self.has_lengthscale:\n",
    "            raise RuntimeError(\"Kernel has no lengthscale.\")\n",
    "\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "\n",
    "        self.initialize(\n",
    "            raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def local_load_samples(self, samples_dict, memo, prefix):\n",
    "        num_samples = next(iter(samples_dict.values())).size(0)\n",
    "        self.batch_shape = torch.Size([num_samples]) + self.batch_shape\n",
    "        super().local_load_samples(samples_dict, memo, prefix)\n",
    "\n",
    "    def covar_dist(\n",
    "        self,\n",
    "        x1,\n",
    "        x2,\n",
    "        diag=False,\n",
    "        last_dim_is_batch=False,\n",
    "        square_dist=True,\n",
    "        dist_postprocess_func=default_postprocess_script,\n",
    "        postprocess=True,\n",
    "        **params,\n",
    "    ):\n",
    "\n",
    "        if last_dim_is_batch:\n",
    "            x1 = x1.transpose(-1, -2).unsqueeze(-1)\n",
    "            x2 = x2.transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        x1_eq_x2 = torch.equal(x1, x2)\n",
    "\n",
    "        # torch scripts expect tensors\n",
    "        postprocess = torch.tensor(postprocess)\n",
    "\n",
    "        res = None\n",
    "\n",
    "        # Cache the Distance object or else JIT will recompile every time\n",
    "        if not self.distance_module or self.distance_module._postprocess != dist_postprocess_func:\n",
    "            self.distance_module = Distance1(dist_postprocess_func)\n",
    "\n",
    "        if diag:\n",
    "            # Special case the diagonal because we can return all zeros most of\n",
    "            # the time.\n",
    "            if x1_eq_x2:\n",
    "                res = torch.zeros(*x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device)\n",
    "                if postprocess:\n",
    "                    res = dist_postprocess_func(res)\n",
    "                return res\n",
    "            else:\n",
    "                res = torch.norm(x1 - x2, p=2, dim=-1)\n",
    "                if square_dist:\n",
    "                    res = res.pow(2)\n",
    "            if postprocess:\n",
    "                res = dist_postprocess_func(res)\n",
    "            return res\n",
    "\n",
    "        elif square_dist:\n",
    "            res = self.distance_module._sq_dist(x1, x2, postprocess, x1_eq_x2)\n",
    "        else:\n",
    "            res = self.distance_module._dist(x1, x2, postprocess, x1_eq_x2)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def named_sub_kernels(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if module is not self and isinstance(module, Kernel):\n",
    "                yield name, module\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        How many outputs are produced per input (default 1)\n",
    "        if x1 is size `n x d` and x2 is size `m x d`, then the size of the kernel\n",
    "        will be `(n * num_outputs_per_input) x (m * num_outputs_per_input)`\n",
    "        Default: 1\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    def prediction_strategy(self, train_inputs, train_prior_dist, train_labels, likelihood):\n",
    "        return exact_prediction_strategies.DefaultPredictionStrategy(\n",
    "            train_inputs, train_prior_dist, train_labels, likelihood\n",
    "        )\n",
    "\n",
    "    def sub_kernels(self):\n",
    "        for _, kernel in self.named_sub_kernels():\n",
    "            yield kernel\n",
    "\n",
    "    def __call__(self, x1, x2=None, diag=False, last_dim_is_batch=False, **params):\n",
    "        x1_, x2_ = x1, x2\n",
    "\n",
    "        # Select the active dimensions\n",
    "        if self.active_dims is not None:\n",
    "            x1_ = x1_.index_select(-1, self.active_dims)\n",
    "            if x2_ is not None:\n",
    "                x2_ = x2_.index_select(-1, self.active_dims)\n",
    "\n",
    "        # Give x1_ and x2_ a last dimension, if necessary\n",
    "        if x1_.ndimension() == 1:\n",
    "            x1_ = x1_.unsqueeze(1)\n",
    "        if x2_ is not None:\n",
    "            if x2_.ndimension() == 1:\n",
    "                x2_ = x2_.unsqueeze(1)\n",
    "            if not x1_.size(-1) == x2_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"x1_ and x2_ must have the same number of dimensions!\")\n",
    "\n",
    "        if x2_ is None:\n",
    "            x2_ = x1_\n",
    "\n",
    "        # Check that ard_num_dims matches the supplied number of dimensions\n",
    "        if settings.debug.on():\n",
    "            if self.ard_num_dims is not None and self.ard_num_dims != x1_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"Expected the input to have {} dimensionality \"\n",
    "                    \"(based on the ard_num_dims argument). Got {}.\".format(\n",
    "                        self.ard_num_dims, x1_.size(-1))\n",
    "                )\n",
    "\n",
    "        if diag:\n",
    "            res = super(Kernel, self).__call__(x1_, x2_, diag=True,\n",
    "                                               last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            # Did this Kernel eat the diag option?\n",
    "            # If it does not return a LazyEvaluatedKernelTensor, we can call\n",
    "            # diag on the output\n",
    "            if not isinstance(res, LazyEvaluatedKernelTensor):\n",
    "                if res.dim() == x1_.dim() and res.shape[-2:] == torch.Size((x1_.size(-2), x2_.size(-2))):\n",
    "                    res = res.diag()\n",
    "            return res\n",
    "\n",
    "        else:\n",
    "            if settings.lazily_evaluate_kernels.on():\n",
    "                res = LazyEvaluatedKernelTensor(\n",
    "                    x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            else:\n",
    "                res = lazify(super(Kernel, self).__call__(\n",
    "                    x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n",
    "            return res\n",
    "\n",
    "    def __getstate__(self):\n",
    "        # JIT ScriptModules cannot be pickled\n",
    "        self.distance_module = None\n",
    "        return self.__dict__\n",
    "\n",
    "    def __add__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, AdditiveKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               AdditiveKernel) else [other]\n",
    "        return AdditiveKernel(*kernels)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, ProductKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               ProductKernel) else [other]\n",
    "        return ProductKernel(*kernels)\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if len(self.batch_shape) == 0:\n",
    "            return self\n",
    "\n",
    "        new_kernel = deepcopy(self)\n",
    "        # Process the index\n",
    "        index = index if isinstance(index, tuple) else (index,)\n",
    "\n",
    "        for param_name, param in self._parameters.items():\n",
    "            new_kernel._parameters[param_name].data = param.__getitem__(index)\n",
    "            ndim_removed = len(param.shape) - \\\n",
    "                len(new_kernel._parameters[param_name].shape)\n",
    "            new_batch_shape_len = len(self.batch_shape) - ndim_removed\n",
    "            new_kernel.batch_shape = new_kernel._parameters[\n",
    "                param_name].shape[:new_batch_shape_len]\n",
    "\n",
    "        for sub_module_name, sub_module in self.named_sub_kernels():\n",
    "            self._modules[sub_module_name] = sub_module.__getitem__(index)\n",
    "\n",
    "        return new_kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "398eaed0-c424-4be0-a050-f69a44570760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gpytorch\n",
    "from gpytorch import settings\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.lazy import LazyEvaluatedKernelTensor, ZeroLazyTensor, delazify, lazify\n",
    "from gpytorch.models import exact_prediction_strategies\n",
    "from gpytorch.module import Module\n",
    "from gpytorch.utils.broadcasting import _mul_broadcast_shape\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def calc_L_polynomial_coeffs():\n",
    "        '''\n",
    "        Calculates the coefficients of the polynomial in L that represent\n",
    "        projection matrices into each of the kth eigenspaces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        B : array-like of shape (seq_length + 1, seq_length + 1)\n",
    "            Matrix containing the b_i,k coefficients for power i on rows\n",
    "            and order k on columns. One can obtain the coefficients for any\n",
    "            combination of $\\lambda_k$ values by scaling the coefficients\n",
    "            for each eigenspace by its eigenvalue and adding them up across\n",
    "            different powers\n",
    "        '''\n",
    "\n",
    "        lambdas = np.array([q**k for k in range(l+1)])\n",
    "        s = l + 1\n",
    "        B = np.zeros((s, s))\n",
    "\n",
    "        idx = np.arange(s)\n",
    "\n",
    "        for k in idx:\n",
    "            k_idx = idx != k\n",
    "            k_lambdas = lambdas[k_idx]\n",
    "            norm_factor = 1 / np.prod(k_lambdas - lambdas[k])\n",
    "\n",
    "            for power in idx:\n",
    "                p = np.sum([np.product(v) for v in combinations(k_lambdas, l - power)])\n",
    "                B[power, k] = norm_factor * (-1) ** (power) * p\n",
    "\n",
    "        return(B)\n",
    "\n",
    "\n",
    "\n",
    "class SkewKernel(Kernel):\n",
    "    \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, alpha, l,\n",
    "                log_lda_prior=None, log_lda_constraint=None, \n",
    "                log_p_prior=None, log_p_constraint=None,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "#         self.odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)])\n",
    "        self.odds = torch.nn.Parameter(torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]), requires_grad=False)\n",
    "        self.scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)])\n",
    "        self.scaling_factors[0] = 1\n",
    "        self.scaling_factors = torch.nn.Parameter(self.scaling_factors, requires_grad=False)\n",
    "        \n",
    "        self.coeffs = torch.tensor(calc_L_polynomial_coeffs(), dtype=torch.float32)\n",
    "        self.coeffs = torch.nn.Parameter(self.coeffs, requires_grad=False)\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "          name='raw_log_p', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l, alpha))\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\n",
    "          name='raw_log_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l+1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if log_lda_constraint is None:\n",
    "          log_lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        if log_p_constraint is None:\n",
    "          log_p_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_log_lda\", log_lda_constraint)\n",
    "        self.register_constraint(\"raw_log_p\", log_p_constraint)\n",
    "\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def log_lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_lda_constraint.transform(self.raw_log_lda)\n",
    "\n",
    "    @property\n",
    "    def log_p(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_p_constraint.transform(self.raw_log_p)\n",
    "\n",
    "    @log_lda.setter\n",
    "    def log_lda(self, value):\n",
    "      return self._set_log_lda(value)\n",
    "\n",
    "    @log_p.setter\n",
    "    def log_p(self, value):\n",
    "      return self._set_log_p(value)\n",
    "\n",
    "    \n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = torch.stack([kernel.covar_dist(x1[:, 1*k: 1*(k+1)], x2[:, 1*k: 1*(k+1)]) for k in range(10)], -1)\n",
    "        \n",
    "#         masks = kernel.covar_dist(x1, x2)\n",
    "    \n",
    "        k = masks[:,:,0]\n",
    "        if diag:\n",
    "            k = k.diag()\n",
    "\n",
    "        \n",
    "#         ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "#         pi = x2*(torch.flatten(ps))\n",
    "#         pi[pi==0.] = 1\n",
    "#         pi = torch.prod(pi, 1)\n",
    "#         Dpi = torch.diag(pi)        \n",
    "\n",
    "#         rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "#         rates = rates/ps\n",
    "#         rates = rates\n",
    "#         rates = torch.flatten(rates, start_dim=1)\n",
    "#         log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "#         out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "#         out = torch.flatten(out, start_dim=3)\n",
    "# #         out[out==0.] = 1.\n",
    "\n",
    "#         powers_nz = torch.exp(torch.sum(out, -1))\n",
    "#         power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "#         powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "#         powers = powers*self.scaling_factors\n",
    "        \n",
    "#         weights = torch.matmul(self.coeffs, torch.exp(self.log_lda))\n",
    "        \n",
    "#         return torch.sum(torch.mul(powers, weights), -1)\n",
    "        \n",
    "        return k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea352837-c142-45d7-b69c-a5eeecd82450",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = SkewKernel(alpha, l).to(output_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d44929-44fb-4f74-8fa0-9caed59f2413",
   "metadata": {},
   "source": [
    "#### Prediction on test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f877e2cc-c1ad-46aa-a0c2-c9521c13b1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise = np.array(dat['std'].iloc[train_ids])**2\n",
    "train_noise = torch.tensor(train_noise, dtype=torch.float32).to(output_device)\n",
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_noise, \n",
    "                                                               learn_additional_noise=True).to(output_device)\n",
    "\n",
    "kernel = SkewKernel(alpha, l, odds)\n",
    "# kernel = kernel.to(output_device)\n",
    "# kernel.raw_log_lda = torch.nn.Parameter(torch.cat((torch.tensor([-100.]), \n",
    "#                                                    -2*torch.arange(l))).to(output_device))\n",
    "model = SkewVCModel(train_x, train_y, likelihood, kernel).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30d0b3e-f13a-4c4a-86c9-a56b23529668",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_size = train_x.shape[0]//2\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.beta_features.checkpoint_kernel(checkpoint_size):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec8ffc9d-4a8c-4c8f-811b-13a9f310af4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 | 21% | 61% |\n",
      "|  1 | 35% |  8% |\n",
      "|  2 | 28% |  8% |\n",
      "|  3 | 27% |  8% |\n",
      "|  4 | 15% |  8% |\n",
      "|  5 | 11% |  8% |\n",
      "|  6 | 55% |  8% |\n",
      "|  7 | 37% |  8% |\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423d9a62-abe9-4437-9dab-a5d38ad97420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-1.7.1",
   "language": "python",
   "name": "pytorch-1.7.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
