{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24208195-1065-4d83-a32d-bf66cedf2e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba11dea6-9477-4402-ad2a-130990b43b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ModuleList\n",
    "from gpytorch.module import Module\n",
    "\n",
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "def default_postprocess_script(x):\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "# class Distance1(torch.nn.Module):\n",
    "#     def __init__(self, postprocess_script=default_postprocess_script):\n",
    "#         super().__init__()\n",
    "#         self._postprocess = postprocess_script\n",
    "\n",
    "#     def _sq_dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        \n",
    "#         res = torch.mul(torch.unsqueeze(x1, 1), torch.unsqueeze(x2, 0))\n",
    "\n",
    "#         if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "#             pass\n",
    "# #             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "#         # Zero out negative values\n",
    "#         res.clamp_min_(0)\n",
    "#         return self._postprocess(res) if postprocess else res\n",
    "\n",
    "#     def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "#         # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "#         res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "#         res = res.clamp_min_(1e-30).sqrt_()\n",
    "#         return self._postprocess(res) if postprocess else res\n",
    "\n",
    "class Distance1(torch.nn.Module):\n",
    "    def __init__(self, postprocess_script=default_postprocess_script):\n",
    "        super().__init__()\n",
    "        self._postprocess = postprocess_script\n",
    "\n",
    "    def _sq_dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch squared cdist once implemented: https://github.com/pytorch/pytorch/pull/25799\n",
    "#         adjustment = x1.mean(-2, keepdim=True)\n",
    "#         x1 = x1 - adjustment\n",
    "#         x2 = x2 - adjustment  # x1 and x2 should be identical in all dims except -2 at this point\n",
    "\n",
    "        # Compute squared distance matrix using quadratic expansion\n",
    "#         x1_norm = x1.pow(2).sum(dim=-1, keepdim=True)\n",
    "#         x1_pad = torch.ones_like(x1_norm)\n",
    "#         if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "#             x2_norm, x2_pad = x1_norm, x1_pad\n",
    "#         else:\n",
    "#             x2_norm = x2.pow(2).sum(dim=-1, keepdim=True)\n",
    "#             x2_pad = torch.ones_like(x2_norm)\n",
    "#         x1_ = torch.cat([-2.0 * x1, x1_norm, x1_pad], dim=-1)\n",
    "#         x2_ = torch.cat([x2, x2_pad, x2_norm], dim=-1)\n",
    "#         res = x1_.matmul(x2_.transpose(-2, -1))\n",
    "        res = x1.matmul(x2.transpose(-2, -1))        \n",
    "\n",
    "        if x1_eq_x2 and not x1.requires_grad and not x2.requires_grad:\n",
    "            pass\n",
    "#             res.diagonal(dim1=-2, dim2=-1).fill_(0)\n",
    "\n",
    "        # Zero out negative values\n",
    "        res.clamp_min_(0)\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    "    def _dist(self, x1, x2, postprocess, x1_eq_x2=False):\n",
    "        # TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\n",
    "        res = self._sq_dist(x1, x2, postprocess=False, x1_eq_x2=x1_eq_x2)\n",
    "        res = res.clamp_min_(1e-30).sqrt_()\n",
    "        return self._postprocess(res) if postprocess else res\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "class Kernel(Module):\n",
    "\n",
    "    has_lengthscale = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ard_num_dims=None,\n",
    "        batch_shape=torch.Size([]),\n",
    "        active_dims=None,\n",
    "        lengthscale_prior=None,\n",
    "        lengthscale_constraint=None,\n",
    "        eps=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super(Kernel, self).__init__()\n",
    "        self._batch_shape = batch_shape\n",
    "        if active_dims is not None and not torch.is_tensor(active_dims):\n",
    "            active_dims = torch.tensor(active_dims, dtype=torch.long)\n",
    "        self.register_buffer(\"active_dims\", active_dims)\n",
    "        self.ard_num_dims = ard_num_dims\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "        param_transform = kwargs.get(\"param_transform\")\n",
    "\n",
    "        if lengthscale_constraint is None:\n",
    "            lengthscale_constraint = Positive()\n",
    "\n",
    "        if param_transform is not None:\n",
    "            warnings.warn(\n",
    "                \"The 'param_transform' argument is now deprecated. If you want to use a different \"\n",
    "                \"transformation, specify a different 'lengthscale_constraint' instead.\",\n",
    "                DeprecationWarning,\n",
    "            )\n",
    "\n",
    "        if self.has_lengthscale:\n",
    "            lengthscale_num_dims = 1 if ard_num_dims is None else ard_num_dims\n",
    "            self.register_parameter(\n",
    "                name=\"raw_lengthscale\",\n",
    "                parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, 1, lengthscale_num_dims)),\n",
    "            )\n",
    "            if lengthscale_prior is not None:\n",
    "                self.register_prior(\n",
    "                    \"lengthscale_prior\", lengthscale_prior, lambda m: m.lengthscale, lambda m, v: m._set_lengthscale(\n",
    "                        v)\n",
    "                )\n",
    "\n",
    "            self.register_constraint(\"raw_lengthscale\", lengthscale_constraint)\n",
    "\n",
    "        self.distance_module = None\n",
    "        # TODO: Remove this on next official PyTorch release.\n",
    "        self.__pdist_supports_batch = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x1, x2, diag=False, last_dim_is_batch=False, **params):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @property\n",
    "    def batch_shape(self):\n",
    "        kernels = list(self.sub_kernels())\n",
    "        if len(kernels):\n",
    "            return _mul_broadcast_shape(self._batch_shape, *[k.batch_shape for k in kernels])\n",
    "        else:\n",
    "            return self._batch_shape\n",
    "\n",
    "    @batch_shape.setter\n",
    "    def batch_shape(self, val):\n",
    "        self._batch_shape = val\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.lengthscale.dtype\n",
    "        else:\n",
    "            for param in self.parameters():\n",
    "                return param.dtype\n",
    "            return torch.get_default_dtype()\n",
    "\n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"\n",
    "        Property to indicate whether kernel is stationary or not.\n",
    "        \"\"\"\n",
    "        return self.has_lengthscale\n",
    "\n",
    "    @property\n",
    "    def lengthscale(self):\n",
    "        if self.has_lengthscale:\n",
    "            return self.raw_lengthscale_constraint.transform(self.raw_lengthscale)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @lengthscale.setter\n",
    "    def lengthscale(self, value):\n",
    "        self._set_lengthscale(value)\n",
    "\n",
    "    def _set_lengthscale(self, value):\n",
    "        if not self.has_lengthscale:\n",
    "            raise RuntimeError(\"Kernel has no lengthscale.\")\n",
    "\n",
    "        if not torch.is_tensor(value):\n",
    "            value = torch.as_tensor(value).to(self.raw_lengthscale)\n",
    "\n",
    "        self.initialize(\n",
    "            raw_lengthscale=self.raw_lengthscale_constraint.inverse_transform(value))\n",
    "\n",
    "    def local_load_samples(self, samples_dict, memo, prefix):\n",
    "        num_samples = next(iter(samples_dict.values())).size(0)\n",
    "        self.batch_shape = torch.Size([num_samples]) + self.batch_shape\n",
    "        super().local_load_samples(samples_dict, memo, prefix)\n",
    "\n",
    "    def covar_dist(\n",
    "        self,\n",
    "        x1,\n",
    "        x2,\n",
    "        diag=False,\n",
    "        last_dim_is_batch=False,\n",
    "        square_dist=True,\n",
    "        dist_postprocess_func=default_postprocess_script,\n",
    "        postprocess=True,\n",
    "        **params,\n",
    "    ):\n",
    "\n",
    "        if last_dim_is_batch:\n",
    "            x1 = x1.transpose(-1, -2).unsqueeze(-1)\n",
    "            x2 = x2.transpose(-1, -2).unsqueeze(-1)\n",
    "\n",
    "        x1_eq_x2 = torch.equal(x1, x2)\n",
    "\n",
    "        # torch scripts expect tensors\n",
    "        postprocess = torch.tensor(postprocess)\n",
    "\n",
    "        res = None\n",
    "\n",
    "        # Cache the Distance object or else JIT will recompile every time\n",
    "        if not self.distance_module or self.distance_module._postprocess != dist_postprocess_func:\n",
    "            self.distance_module = Distance1(dist_postprocess_func)\n",
    "\n",
    "        if diag:\n",
    "            # Special case the diagonal because we can return all zeros most of\n",
    "            # the time.\n",
    "            if x1_eq_x2:\n",
    "                res = torch.zeros(*x1.shape[:-2], x1.shape[-2], dtype=x1.dtype, device=x1.device)\n",
    "                if postprocess:\n",
    "                    res = dist_postprocess_func(res)\n",
    "                return res\n",
    "            else:\n",
    "                res = torch.norm(x1 - x2, p=2, dim=-1)\n",
    "                if square_dist:\n",
    "                    res = res.pow(2)\n",
    "            if postprocess:\n",
    "                res = dist_postprocess_func(res)\n",
    "            return res\n",
    "\n",
    "        elif square_dist:\n",
    "            res = self.distance_module._sq_dist(x1, x2, postprocess, x1_eq_x2)\n",
    "        else:\n",
    "            res = self.distance_module._dist(x1, x2, postprocess, x1_eq_x2)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def named_sub_kernels(self):\n",
    "        for name, module in self.named_modules():\n",
    "            if module is not self and isinstance(module, Kernel):\n",
    "                yield name, module\n",
    "\n",
    "    def num_outputs_per_input(self, x1, x2):\n",
    "        \"\"\"\n",
    "        How many outputs are produced per input (default 1)\n",
    "        if x1 is size `n x d` and x2 is size `m x d`, then the size of the kernel\n",
    "        will be `(n * num_outputs_per_input) x (m * num_outputs_per_input)`\n",
    "        Default: 1\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "    def prediction_strategy(self, train_inputs, train_prior_dist, train_labels, likelihood):\n",
    "        return exact_prediction_strategies.DefaultPredictionStrategy(\n",
    "            train_inputs, train_prior_dist, train_labels, likelihood\n",
    "        )\n",
    "\n",
    "    def sub_kernels(self):\n",
    "        for _, kernel in self.named_sub_kernels():\n",
    "            yield kernel\n",
    "\n",
    "    def __call__(self, x1, x2=None, diag=False, last_dim_is_batch=False, **params):\n",
    "        x1_, x2_ = x1, x2\n",
    "\n",
    "        # Select the active dimensions\n",
    "        if self.active_dims is not None:\n",
    "            x1_ = x1_.index_select(-1, self.active_dims)\n",
    "            if x2_ is not None:\n",
    "                x2_ = x2_.index_select(-1, self.active_dims)\n",
    "\n",
    "        # Give x1_ and x2_ a last dimension, if necessary\n",
    "        if x1_.ndimension() == 1:\n",
    "            x1_ = x1_.unsqueeze(1)\n",
    "        if x2_ is not None:\n",
    "            if x2_.ndimension() == 1:\n",
    "                x2_ = x2_.unsqueeze(1)\n",
    "            if not x1_.size(-1) == x2_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"x1_ and x2_ must have the same number of dimensions!\")\n",
    "\n",
    "        if x2_ is None:\n",
    "            x2_ = x1_\n",
    "\n",
    "        # Check that ard_num_dims matches the supplied number of dimensions\n",
    "        if settings.debug.on():\n",
    "            if self.ard_num_dims is not None and self.ard_num_dims != x1_.size(-1):\n",
    "                raise RuntimeError(\n",
    "                    \"Expected the input to have {} dimensionality \"\n",
    "                    \"(based on the ard_num_dims argument). Got {}.\".format(\n",
    "                        self.ard_num_dims, x1_.size(-1))\n",
    "                )\n",
    "\n",
    "        if diag:\n",
    "            res = super(Kernel, self).__call__(x1_, x2_, diag=True,\n",
    "                                               last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            # Did this Kernel eat the diag option?\n",
    "            # If it does not return a LazyEvaluatedKernelTensor, we can call\n",
    "            # diag on the output\n",
    "            if not isinstance(res, LazyEvaluatedKernelTensor):\n",
    "                if res.dim() == x1_.dim() and res.shape[-2:] == torch.Size((x1_.size(-2), x2_.size(-2))):\n",
    "                    res = res.diag()\n",
    "            return res\n",
    "\n",
    "        else:\n",
    "            if settings.lazily_evaluate_kernels.on():\n",
    "                res = LazyEvaluatedKernelTensor(\n",
    "                    x1_, x2_, kernel=self, last_dim_is_batch=last_dim_is_batch, **params)\n",
    "            else:\n",
    "                res = lazify(super(Kernel, self).__call__(\n",
    "                    x1_, x2_, last_dim_is_batch=last_dim_is_batch, **params))\n",
    "            return res\n",
    "\n",
    "    def __getstate__(self):\n",
    "        # JIT ScriptModules cannot be pickled\n",
    "        self.distance_module = None\n",
    "        return self.__dict__\n",
    "\n",
    "    def __add__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, AdditiveKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               AdditiveKernel) else [other]\n",
    "        return AdditiveKernel(*kernels)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        kernels = []\n",
    "        kernels += self.kernels if isinstance(self, ProductKernel) else [self]\n",
    "        kernels += other.kernels if isinstance(other,\n",
    "                                               ProductKernel) else [other]\n",
    "        return ProductKernel(*kernels)\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self.__dict__ = d\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if len(self.batch_shape) == 0:\n",
    "            return self\n",
    "\n",
    "        new_kernel = deepcopy(self)\n",
    "        # Process the index\n",
    "        index = index if isinstance(index, tuple) else (index,)\n",
    "\n",
    "        for param_name, param in self._parameters.items():\n",
    "            new_kernel._parameters[param_name].data = param.__getitem__(index)\n",
    "            ndim_removed = len(param.shape) - \\\n",
    "                len(new_kernel._parameters[param_name].shape)\n",
    "            new_batch_shape_len = len(self.batch_shape) - ndim_removed\n",
    "            new_kernel.batch_shape = new_kernel._parameters[\n",
    "                param_name].shape[:new_batch_shape_len]\n",
    "\n",
    "        for sub_module_name, sub_module in self.named_sub_kernels():\n",
    "            self._modules[sub_module_name] = sub_module.__getitem__(index)\n",
    "\n",
    "        return new_kernel\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "from gpytorch import settings\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.lazy import LazyEvaluatedKernelTensor, ZeroLazyTensor, delazify, lazify\n",
    "from gpytorch.models import exact_prediction_strategies\n",
    "from gpytorch.module import Module\n",
    "from gpytorch.utils.broadcasting import _mul_broadcast_shape\n",
    "from gpytorch.constraints import Positive\n",
    "from gpytorch.constraints import LessThan\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "def calc_L_polynomial_coeffs():\n",
    "        '''\n",
    "        Calculates the coefficients of the polynomial in L that represent\n",
    "        projection matrices into each of the kth eigenspaces.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        B : array-like of shape (seq_length + 1, seq_length + 1)\n",
    "            Matrix containing the b_i,k coefficients for power i on rows\n",
    "            and order k on columns. One can obtain the coefficients for any\n",
    "            combination of $\\lambda_k$ values by scaling the coefficients\n",
    "            for each eigenspace by its eigenvalue and adding them up across\n",
    "            different powers\n",
    "        '''\n",
    "\n",
    "        lambdas = np.array([q**k for k in range(l+1)])\n",
    "        s = l + 1\n",
    "        B = np.zeros((s, s))\n",
    "\n",
    "        idx = np.arange(s)\n",
    "\n",
    "        for k in idx:\n",
    "            k_idx = idx != k\n",
    "            k_lambdas = lambdas[k_idx]\n",
    "            norm_factor = 1 / np.prod(k_lambdas - lambdas[k])\n",
    "\n",
    "            for power in idx:\n",
    "                p = np.sum([np.product(v) for v in combinations(k_lambdas, l - power)])\n",
    "                B[power, k] = norm_factor * (-1) ** (power) * p\n",
    "\n",
    "        return(B)\n",
    "\n",
    "\n",
    "class SkewVCModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood, ker):\n",
    "        super(SkewVCModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "#         base_covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        base_covar_module = ker\n",
    "\n",
    "\n",
    "        self.covar_module = gpytorch.kernels.MultiDeviceKernel(\n",
    "            base_covar_module, device_ids=range(n_devices),\n",
    "            output_device=output_device\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "\n",
    "\n",
    "def train_model(model, likelihood, train_x, train_y, checkpoint_size, preconditioner_size, training_iter=300, lr=.05):\n",
    "    losses = []\n",
    "    \n",
    "    \"\"\"fitting hyperparameters of model by maximizing marginal log likelihood\"\"\"\n",
    "    # Use the adam optimizer, this includes GaussianLikelihood parameters\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "\n",
    "\n",
    "    # \"Loss\" for GPs - the marginal log likelihood\n",
    "    mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "    for i in range(training_iter):\n",
    "      if i%2000==0:\n",
    "        print(i)\n",
    "      else: pass\n",
    "      # Zero gradients from previous iteration\n",
    "    with gpytorch.beta_features.checkpoint_kernel(checkpoint_size):\n",
    "    \n",
    "#     with gpytorch.beta_features.checkpoint_kernel(checkpoint_size), \\\n",
    "#          gpytorch.settings.max_preconditioner_size(preconditioner_size):        \n",
    "        optimizer.zero_grad()\n",
    "        # Output from model\n",
    "        output = model(train_x)\n",
    "        # Calc loss and backprop gradients\n",
    "        loss = -mll(output, train_y)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "#         losses.append(loss.item())    \n",
    "        optimizer.step()\n",
    "        del loss\n",
    "#     return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af93ae9-0741-41d3-a86b-2e32d007c505",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f2e9b9-6384-4e4d-8146-47d5ef255594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning to run on 8 GPUs.\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n",
      "|  1 |  0% |  2% |\n",
      "|  2 |  0% |  2% |\n",
      "|  3 |  0% |  2% |\n",
      "|  4 |  0% |  2% |\n",
      "|  5 |  0% |  2% |\n",
      "|  6 |  0% |  2% |\n",
      "|  7 |  0% |  2% |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_129092/3655052498.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import GPUtil\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "output_device = torch.device('cuda:0')\n",
    "print('Planning to run on {} GPUs.'.format(n_devices))\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "alpha = 4\n",
    "l = 8\n",
    "alphabet = list(range(alpha))\n",
    "\n",
    "# prob no mutation at time 1\n",
    "# q = 1 - 1/l\n",
    "q = 0.7\n",
    "\n",
    "odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]).to(output_device)\n",
    "\n",
    "scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)]).to(output_device)\n",
    "scaling_factors[0] = 1\n",
    "\n",
    "seqs = list(itertools.product(alphabet, repeat=l))\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "seqs1h_test = torch.flatten(torch.tensor(F.one_hot(seqs), dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "seqs2 = []\n",
    "for d in range(0, l+1):\n",
    "    seq = torch.zeros(l)\n",
    "    seq[:d] = 3\n",
    "    seqs2.append(seq)\n",
    "\n",
    "seqs2 = torch.stack(seqs2).type(torch.int64)\n",
    "\n",
    "x1 = seqs1h_test[:10]\n",
    "x2 = F.one_hot(seqs2).type(torch.float32).to(output_device)\n",
    "x2 = torch.flatten(x2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048298e-d144-463d-9537-319bef7dcf5d",
   "metadata": {},
   "source": [
    "## SMN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a939223d-29a2-4faf-9be2-e83a9dd220bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/46713648/ipykernel_129092/4083788742.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dat = pd.read_csv(\"Smn1Data.txt\", header=None)\n",
    "\n",
    "dat = dat.rename(columns={0:\"seq\", 1:\"psi\", 2:\"std\", 3:\"gene\"})\n",
    "dat['seq']=[seq[:3] + seq[4:] for seq in dat['seq']]\n",
    "\n",
    "from collections import OrderedDict\n",
    "IUPAC_VOCAB_ = OrderedDict([\n",
    "    (\"A\", 0),\n",
    "    (\"U\", 1),\n",
    "    (\"C\", 2),\n",
    "    (\"G\", 3)])\n",
    "\n",
    "def tokenize(seq):\n",
    "    return [IUPAC_VOCAB_[char] for char in seq]\n",
    "\n",
    "seqs = [tokenize(seq) for seq in dat.seq]\n",
    "seqs = torch.tensor(seqs).to(output_device)\n",
    "\n",
    "seqs1h = torch.flatten(torch.tensor(F.one_hot(seqs),dtype=torch.float32), start_dim=1).to(output_device)\n",
    "\n",
    "y = torch.tensor(dat.psi, dtype=torch.float32).to(output_device)\n",
    "\n",
    "import random\n",
    "train_size = 25000\n",
    "train_ids = random.sample(range(len(seqs1h)), train_size)\n",
    "test_ids = random.sample(list(set(range((len(seqs1h)))).difference(train_ids)), dat.shape[0] - train_size)\n",
    "\n",
    "train_x, test_x = seqs1h[train_ids], seqs1h[test_ids]\n",
    "train_y, test_y = y[train_ids], y[test_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30870221-2da7-48d5-913a-b0cfcc4eb94e",
   "metadata": {},
   "source": [
    "#### Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cd161a5-e700-4a67-850e-35ad86913870",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkewKernel(Kernel):\n",
    "    \"\"\"Diploid kernel\"\"\"\n",
    "\n",
    "    is_stationary = True\n",
    "\n",
    "    # We will register the parameter when initializing the kernel\n",
    "    def __init__(self, alpha, l,\n",
    "                log_lda_prior=None, log_lda_constraint=None, \n",
    "                log_p_prior=None, log_p_constraint=None,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "#         self.odds = torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)])\n",
    "        self.odds = torch.nn.Parameter(torch.tensor([q**t/(1 - q**t) for t in range(1, l+1)]), requires_grad=False)\n",
    "        self.scaling_factors = torch.tensor([(1 - q**t)**l for t in range(l+1)])\n",
    "        self.scaling_factors[0] = 1\n",
    "        self.scaling_factors = torch.nn.Parameter(self.scaling_factors, requires_grad=False)\n",
    "        \n",
    "        self.coeffs = torch.tensor(calc_L_polynomial_coeffs(), dtype=torch.float32)\n",
    "        self.coeffs = torch.nn.Parameter(self.coeffs, requires_grad=False)\n",
    "        # register the raw parameter\n",
    "        self.register_parameter(\n",
    "          name='raw_log_p', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l, alpha), requires_grad=True)\n",
    "        )\n",
    "\n",
    "        self.register_parameter(\n",
    "          name='raw_log_lda', \n",
    "          parameter=torch.nn.Parameter(torch.zeros(*self.batch_shape, l+1))\n",
    "        )\n",
    "\n",
    "        # set the parameter constraint to be positive, when nothing is specified\n",
    "        if log_lda_constraint is None:\n",
    "          log_lda_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        if log_p_constraint is None:\n",
    "          log_p_constraint = LessThan(upper_bound=0.)\n",
    "\n",
    "        # register the constraint\n",
    "        self.register_constraint(\"raw_log_lda\", log_lda_constraint)\n",
    "        self.register_constraint(\"raw_log_p\", log_p_constraint)\n",
    "\n",
    "\n",
    "    # now set up the 'actual' paramter\n",
    "    @property\n",
    "    def log_lda(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_lda_constraint.transform(self.raw_log_lda)\n",
    "\n",
    "    @property\n",
    "    def log_p(self):\n",
    "      # when accessing the parameter, apply the constraint transform\n",
    "      return self.raw_log_p_constraint.transform(self.raw_log_p)\n",
    "\n",
    "    @log_lda.setter\n",
    "    def log_lda(self, value):\n",
    "      return self._set_log_lda(value)\n",
    "\n",
    "    @log_p.setter\n",
    "    def log_p(self, value):\n",
    "      return self._set_log_p(value)\n",
    "\n",
    "    def func(self, x1, x2, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "        ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "        pi = x2*(torch.flatten(ps))\n",
    "        pi[pi==0.] = 1\n",
    "        pi = torch.prod(pi, 1)\n",
    "        Dpi = torch.diag(pi)        \n",
    "\n",
    "        rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "        rates = rates/ps\n",
    "        rates = rates\n",
    "        rates = torch.flatten(rates, start_dim=1)\n",
    "        log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "        out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "        out = torch.flatten(out, start_dim=3)\n",
    "\n",
    "        powers_nz = torch.exp(torch.sum(out, -1))\n",
    "        power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "        powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "        powers = powers*scaling_factors\n",
    "        \n",
    "        return powers_nz, powers, rates\n",
    "\n",
    "    \n",
    "    def forward(self, x1, x2, diag=False, **params):\n",
    "        # construct masks used for calculate rates\n",
    "        masks = self.covar_dist(x1, x2)\n",
    "#         ps = torch.softmax(self.log_p, axis=1)\n",
    "        \n",
    "#         pi = x2*(torch.flatten(ps))\n",
    "#         pi[pi==0.] = 1\n",
    "#         pi = torch.prod(pi, 1)\n",
    "#         Dpi = torch.diag(pi)        \n",
    "\n",
    "#         rates = self.odds.unsqueeze(1).unsqueeze(-1)  + torch.unsqueeze(ps, 0)\n",
    "#         rates = rates/ps\n",
    "#         rates = rates\n",
    "#         rates = torch.flatten(rates, start_dim=1)\n",
    "#         log_rates = torch.log(rates)\n",
    "        \n",
    "\n",
    "#         out = torch.mul(masks.unsqueeze(2), log_rates)\n",
    "#         out = torch.flatten(out, start_dim=3)\n",
    "# #         out[out==0.] = 1.\n",
    "\n",
    "#         powers_nz = torch.exp(torch.sum(out, -1))\n",
    "#         power_0 = F.relu(torch.sum(masks, -1) - l + 1).matmul(torch.linalg.inv(Dpi))\n",
    "#         powers = torch.cat([power_0.unsqueeze(-1), powers_nz], dim=-1)\n",
    "#         powers = powers*self.scaling_factors\n",
    "        \n",
    "#         weights = torch.matmul(self.coeffs, torch.exp(self.log_lda))\n",
    "        \n",
    "        k = torch.exp(-2*torch.sum(masks, -1))\n",
    "        \n",
    "        if diag: \n",
    "            k = k[0]\n",
    "        \n",
    "        return k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d01a509-10c2-468a-b7b2-875154fdf0db",
   "metadata": {},
   "source": [
    "#### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "049d0b23-6fd3-4165-851c-740b85f936c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_noise = np.array(dat['std'].iloc[train_ids])**2\n",
    "train_noise = torch.tensor(train_noise, dtype=torch.float32).to(output_device)\n",
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=train_noise, \n",
    "                                                               learn_additional_noise=True).to(output_device)\n",
    "\n",
    "kernel = SkewKernel(alpha, l, odds)\n",
    "# kernel = kernel.to(output_device)\n",
    "kernel.raw_log_lda = torch.nn.Parameter(torch.cat((torch.tensor([-100.]), \n",
    "                                                   -2*torch.arange(l))).to(output_device))\n",
    "model = SkewVCModel(train_x, train_y, likelihood, kernel).to(output_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51804027-e2be-4297-838f-ddfcbbc3e96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.33 GiB (GPU 0; 79.35 GiB total capacity; 74.53 GiB already allocated; 1.12 GiB free; 74.55 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/46713648/ipykernel_129092/592796382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Make predictions on a small number of test points to get the test time caches computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mf_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_gp.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;31m# Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_eval_tolerance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0mpredictive_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictive_covar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# Reshape predictive mean to match the appropriate event shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_prediction\u001b[0;34m(self, joint_mean, joint_covar)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         return (\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexact_predictive_covar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_test_covar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_train_covar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mexact_predictive_mean\u001b[0;34m(self, test_mean, test_train_covar)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# You **cannot* use addmv here, because test_train_covar may not actually be a non lazy tensor even for an exact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;31m# GP, and using addmv requires you to delazify test_train_covar, which is obviously a huge no-no!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_train_covar\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/models/exact_prediction_strategies.py\u001b[0m in \u001b[0;36mmean_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mtrain_labels_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mmean_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_train_covar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels_offset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_test_caches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36minv_matmul\u001b[0;34m(self, right_tensor, left_tensor)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInvMatmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, representation_tree, has_left, *args)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleft_tensor\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0msolves\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_tsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/functions/_inv_matmul.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(lazy_tsr, rhs)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpreconditioner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inv_matmul_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlazy_tsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreconditioner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_inv_matmul_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mon\u001b[0m \u001b[0mx\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mperforms\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \"\"\"\n\u001b[0;32m--> 448\u001b[0;31m         \u001b[0mbase_precond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preconditioner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbase_precond\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/added_diag_lazy_tensor.py\u001b[0m in \u001b[0;36m_preconditioner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_q_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_preconditioner_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivoted_cholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_piv_chol_self\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 warnings.warn(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/pivoted_cholesky.py\u001b[0m in \u001b[0;36mpivoted_cholesky\u001b[0;34m(matrix, max_iter, error_tol)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# LazyTensor.diag() operates in batch mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlazify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmatrix_diag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_approx_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Make sure max_iter isn't bigger than the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py\u001b[0m in \u001b[0;36m_approx_diag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0mof\u001b[0m \u001b[0mdiagonals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \"\"\"\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cholesky\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/utils/memoize.py\u001b[0m in \u001b[0;36mg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mkwargs_pkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_in_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_add_to_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs_pkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/lazy/lazy_evaluated_kernel_tensor.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         res = super(Kernel, self.kernel).__call__(\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dim_is_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_validate_module_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gpytorch/kernels/multi_device_kernel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/local/46713648/ipykernel_129092/992587594.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, diag, **params)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#         weights = torch.matmul(self.coeffs, torch.exp(self.log_lda))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.33 GiB (GPU 0; 79.35 GiB total capacity; 74.53 GiB already allocated; 1.12 GiB free; 74.55 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "checkpoint_size = train_x.shape[0]//4\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "test_x = test_x.cuda()\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.beta_features.checkpoint_kernel(checkpoint_size):\n",
    "    # Make predictions on a small number of test points to get the test time caches computed\n",
    "    f_preds = model(test_x)\n",
    "\n",
    "\n",
    "f_mean = f_preds.mean.cpu().detach().numpy()\n",
    "y_test = test_y.detach().cpu().numpy()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# epistatic\n",
    "# figure(figsize=(5, 5), dpi=80)\n",
    "plt.axes().set_aspect('equal')\n",
    "plt.xlim([-10, 200])\n",
    "plt.ylim([-10, 200])\n",
    "\n",
    "plt.plot(f_mean, y_test, 'o', alpha=.3)\n",
    "\n",
    "plt.show()\n",
    "print('R2 = %f'%r2_score(y_test, f_mean))\n",
    "print('r2 = %f'%pearsonr(y_test, f_mean)[0]**2)\n",
    "# print('mse = %f'%mse(f_mean, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06637fb7-7dba-471e-aac9-268fbd9f22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 99% |\n",
      "|  1 |  0% |  2% |\n",
      "|  2 |  0% |  2% |\n",
      "|  3 |  0% |  2% |\n",
      "|  4 |  0% |  2% |\n",
      "|  5 |  0% |  2% |\n",
      "|  6 |  0% |  2% |\n",
      "|  7 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8438db-f823-4b16-98ca-435fe1f30bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3277, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "816ecb88-57b4-46ed-8bc8-ae90541225f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3277, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2107f32-5e5a-4826-af8e-0efdedcd1e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
